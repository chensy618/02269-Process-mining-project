{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fetch and save prerequisites for all courses in the dataset",
   "id": "471a41f91290d00b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Idea and structure by me and most code by Chatgpt",
   "id": "84b0c3fbf61e45ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T16:34:09.463597Z",
     "start_time": "2024-10-13T16:34:08.729992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json"
   ],
   "id": "97802215da9b27f2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Download the prerequisites data from the course page  ",
   "id": "e68eee906582a384"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "changed_rows = 0\n",
    "dropped_rows = 0\n",
    "\n",
    "\n",
    "# Function to process 'KURSKODE'\n",
    "def transform_kurskode(code):\n",
    "    global changed_rows\n",
    "    # Check if it starts with a number\n",
    "    if not code[0].isdigit():\n",
    "        return np.nan  # Mark for dropping\n",
    "    original_code = code\n",
    "    # Pad with 0 if less than 5 characters\n",
    "    if len(code) < 5:\n",
    "        code = code.zfill(5)\n",
    "    # Trim to 5 characters if more than 5\n",
    "    elif len(code) > 5:\n",
    "        code = code[:5]\n",
    "    if code != original_code:\n",
    "        changed_rows += 1\n",
    "    return code\n",
    "\n",
    "\n",
    "def process_kurskode(code):\n",
    "    # Load your CSV file into a DataFrame\n",
    "    df = pd.read_csv('20221012_karakterdata til studenterprojekt.csv')\n",
    "\n",
    "    # Initialize counters for statistics\n",
    "    total_rows = len(df)\n",
    "\n",
    "\n",
    "    # Apply the transformation\n",
    "    df['KURSKODE'] = df['KURSKODE'].astype(str).apply(transform_kurskode)\n",
    "\n",
    "    # Drop rows where KURSKODE is NaN (i.e., where it started with a non-digit)\n",
    "    df.dropna(subset=['KURSKODE'], inplace=True)\n",
    "\n",
    "    # Drop duplicate rows based on 'KURSKODE' to retain unique values\n",
    "    df.drop_duplicates(subset=['KURSKODE'], inplace=True)\n",
    "\n",
    "    # Update the dropped_rows count after dropping duplicates\n",
    "    dropped_rows = total_rows - len(df)\n",
    "\n",
    "    # Convert the 'KURSKODE' column to a numpy array\n",
    "    kurskode_array = df['KURSKODE'].to_numpy()\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"Total rows read: {total_rows}\")\n",
    "    print(f\"Rows changed: {changed_rows}\")\n",
    "    print(f\"Rows dropped: {dropped_rows}\")\n",
    "    print(f\"Unique Rows remaining: {len(df)}\")\n",
    "\n",
    "    # Save the numpy array if needed\n",
    "    np.save('kurskode_array.npy', kurskode_array)\n",
    "\n",
    "\n",
    "# Function to extract academic prerequisites from a course page\n",
    "def extract_prerequisites(course_code, start_year=2023, end_year=2005):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36',\n",
    "        'Accept-Language': 'da-DK,da;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "        'Accept-Encoding': 'gzip, deflate, br, zstd',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Cookie': 'ASP.NET_SessionId=u3wwy3s2suujmsoep02sby0l; SRV_ID=2; {DTUCoursesPublicLanguage}=en-GB',\n",
    "    }\n",
    "\n",
    "    cookies = {\n",
    "        'ASP.NET_SessionId': 'u3wwy3s2suujmsoep02sby0l',\n",
    "        'SRV_ID': '2',\n",
    "        '{DTUCoursesPublicLanguage}': 'en-GB',\n",
    "    }\n",
    "\n",
    "    # First, check the latest version of the course (current year)\n",
    "    url = f'https://kurser.dtu.dk/course/{course_code}'\n",
    "    response = requests.get(url, headers=headers, cookies=cookies)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        return None, f\"Failed to retrieve course {course_code}\"\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Check for multiple possible labels\n",
    "    possible_labels = [\"Academic prerequisites\", \"Recommended prerequisites\", \"Mandatory Prerequisites\"]\n",
    "\n",
    "    for label_text in possible_labels:\n",
    "        prerequisites_label = soup.find('label', text=label_text)\n",
    "        if prerequisites_label:\n",
    "            prerequisites_cell = prerequisites_label.find_next('td')\n",
    "            if prerequisites_cell:\n",
    "                prerequisites_text = prerequisites_cell.get_text(strip=True)\n",
    "                return prerequisites_text, None\n",
    "\n",
    "    # If no prerequisites found in the latest year, try going back to previous years\n",
    "    for year in range(start_year, end_year - 1, -1):\n",
    "        historical_url = f'https://kurser.dtu.dk/course/{year}-{year+1}/{course_code}'\n",
    "        print(f\"Checking for course {course_code} in academic year {year}-{year+1}\")\n",
    "        response = requests.get(historical_url, headers=headers, cookies=cookies)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            for label_text in possible_labels:\n",
    "                prerequisites_label = soup.find('label', text=label_text)\n",
    "                if prerequisites_label:\n",
    "                    prerequisites_cell = prerequisites_label.find_next('td')\n",
    "                    if prerequisites_cell:\n",
    "                        prerequisites_text = prerequisites_cell.get_text(strip=True)\n",
    "                        return prerequisites_text, None\n",
    "\n",
    "    # If no prerequisites found across years\n",
    "    return None, f\"Prerequisites not found for course {course_code} even in older versions\"\n",
    "\n",
    "\n",
    "# List of course codes to process\n",
    "course_codes = np.load('kurskode_array.npy', allow_pickle=True)\n",
    "# course_codes = course_codes[:100]  # Limit to 10 for testing\n",
    "\n",
    "# Arrays to store course data\n",
    "general_rule_courses = []\n",
    "special_treatment_courses = []  # This will store both the course code and the reason\n",
    "\n",
    "# Process each course\n",
    "for course_code in course_codes:\n",
    "    prerequisites_text, special_case = extract_prerequisites(course_code)\n",
    "\n",
    "    if prerequisites_text:\n",
    "        # Append the course and its prerequisites text to the general rule courses\n",
    "        general_rule_courses.append((course_code, prerequisites_text))\n",
    "    else:\n",
    "        # Append both course code and reason to special_treatment_courses\n",
    "        special_treatment_courses.append({\n",
    "            \"course_code\": course_code,\n",
    "            \"reason\": special_case\n",
    "        })\n",
    "\n",
    "# Save the general rule courses to a numpy array and CSV\n",
    "general_rule_array = np.array(general_rule_courses, dtype=object)\n",
    "np.save('general_rule_array.npy', general_rule_array)\n",
    "df = pd.DataFrame(general_rule_array, columns=['Course', 'Prerequisites'])\n",
    "df.to_csv('general_rule_courses.csv', index=False)\n",
    "\n",
    "# Save the general rule courses in JSON Lines format\n",
    "with open('general_rule_courses.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for course in general_rule_courses:\n",
    "        f.write(json.dumps(course, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Print stats\n",
    "print(f\"Total courses processed: {len(course_codes)}\")\n",
    "print(f\"Courses with academic prerequisites text saved: {len(general_rule_courses)}\")\n",
    "print(f\"Courses for special treatment: {len(special_treatment_courses)}\")\n",
    "\n",
    "# Save the special treatment courses to a numpy array\n",
    "special_treatment_array = np.array(special_treatment_courses, dtype=object)\n",
    "np.save('special_treatment_array.npy', special_treatment_array)\n",
    "\n",
    "# Convert to DataFrame and save as CSV\n",
    "df = pd.DataFrame(special_treatment_courses)\n",
    "df.to_csv('special_treatment_courses.csv', index=False)\n",
    "\n",
    "# Save the special treatment courses in JSON Lines format\n",
    "with open('special_treatment_courses.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for course in special_treatment_courses:\n",
    "        f.write(json.dumps(course, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "print(\"\\nCourses requiring special treatment:\")\n",
    "for course in special_treatment_courses:\n",
    "    print(f\"Course {course['course_code']}: {course['reason']}\")\n"
   ],
   "id": "104547a521d5da6a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Extract prerequisites from the following rules                                                     \n",
    "Commas(,) and periods(.) mean AND.                                                                  \n",
    "Slashes( /) and the word “eller” mean OR.                                                           \n",
    "Course numbers prefixed by a dash(-) should have the dash removed.          \n",
    "Course numbers should be exactly 5 digits, with a leading 0 added if they are only 4 digits.                                                 "
   ],
   "id": "3be29e9d0efba202"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T16:34:13.969072Z",
     "start_time": "2024-10-13T16:34:13.922966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the CSV file\n",
    "file_path = 'general_rule_courses.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the special treatment courses\n",
    "special_treatment_file_path = 'special_treatment_courses.csv'\n",
    "special_treatment_df = pd.read_csv(special_treatment_file_path)\n",
    "\n",
    "\n",
    "# Function to clean course numbers by removing \"-\" and ensuring 5 digits with leading zeros\n",
    "def clean_course_number(course):\n",
    "    course = course.strip()  # remove any surrounding whitespace\n",
    "    course = course.lstrip('-')  # remove leading dash if present\n",
    "    if len(course) == 4:\n",
    "        course = '0' + course  # add leading zero if only 4 digits\n",
    "    return course\n",
    "\n",
    "\n",
    "# Function to process prerequisites with parentheses for grouping\n",
    "def parse_prerequisites(prerequisites_text):\n",
    "    # Replace \"eller\" with \"/\"\n",
    "    prerequisites_text = prerequisites_text.replace('eller', '/')\n",
    "\n",
    "    # Split based on AND operators (commas and periods)\n",
    "    parts = re.split(r'[,\\.]', prerequisites_text)\n",
    "    parsed_prerequisites = []\n",
    "    invalid_cases = []\n",
    "\n",
    "    for part in parts:\n",
    "        part = part.strip()  # Clean up any extra spaces\n",
    "        # Split on OR indicators within each part\n",
    "        sub_parts = re.split(r'[\\/]', part)\n",
    "        cleaned_sub_parts = []\n",
    "\n",
    "        for sub_part in sub_parts:\n",
    "            # Extract valid course numbers (should be 4 or 5 digits)\n",
    "            course_numbers = re.findall(r'\\d{4,5}', sub_part)\n",
    "            if course_numbers:\n",
    "                cleaned_sub_parts.append(' or '.join([clean_course_number(num) for num in course_numbers]))\n",
    "            else:\n",
    "                invalid_cases.append(sub_part.strip())  # Capture invalid cases\n",
    "\n",
    "        if cleaned_sub_parts:\n",
    "            # Join sub-parts (OR parts) with parentheses\n",
    "            parsed_prerequisites.append(f\"({' or '.join(cleaned_sub_parts)})\")\n",
    "\n",
    "    # Join the AND parts\n",
    "    return ' and '.join(parsed_prerequisites), invalid_cases\n",
    "\n",
    "\n",
    "# Prepare lists to hold different categories\n",
    "valid_prerequisites = []\n",
    "no_prerequisites = []\n",
    "further_processing = []\n",
    "\n",
    "# Process each course and its prerequisites\n",
    "for index, row in df.iterrows():\n",
    "    course_code = str(row['Course'])\n",
    "    prerequisites_text = row['Prerequisites']\n",
    "\n",
    "    # Check if the prerequisites are \"None\" or empty\n",
    "    if pd.isna(prerequisites_text) or prerequisites_text.strip().lower() == 'none':\n",
    "        no_prerequisites.append({\"course_code\": course_code})\n",
    "    else:\n",
    "        parsed, invalid = parse_prerequisites(prerequisites_text)\n",
    "\n",
    "        # If there are valid parsed prerequisites, add them to the valid list\n",
    "        if parsed and not invalid:\n",
    "            valid_prerequisites.append({\"course_code\": course_code, \"parsed_prerequisites\": parsed})\n",
    "        elif parsed:\n",
    "            # If valid prerequisites are found, only add to the valid list, not further processing\n",
    "            valid_prerequisites.append({\"course_code\": course_code, \"parsed_prerequisites\": parsed})\n",
    "        else:\n",
    "            # If no valid prerequisites, add to further processing\n",
    "            further_processing.append({\"course_code\": course_code, \"invalid_prerequisites\": invalid})\n",
    "\n",
    "# Add the courses from the special_treatment_courses.csv to the no_prerequisites list\n",
    "for index, row in special_treatment_df.iterrows():\n",
    "    course_code = str(row['course_code'])\n",
    "    no_prerequisites.append({\"course_code\": course_code})\n",
    "\n",
    "# Save files for no prerequisites, valid prerequisites, and further processing\n",
    "\n",
    "# Save no prerequisites to JSON Lines\n",
    "no_prerequisites_file = 'no_prerequisites.jsonl'\n",
    "with open(no_prerequisites_file, 'w', encoding='utf-8') as f:\n",
    "    for entry in no_prerequisites:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Save valid prerequisites to JSON Lines\n",
    "valid_prerequisites_file = 'valid_prerequisites.jsonl'\n",
    "with open(valid_prerequisites_file, 'w', encoding='utf-8') as f:\n",
    "    for entry in valid_prerequisites:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Save courses needing further processing to JSON Lines\n",
    "further_processing_file = 'further_processing.jsonl'\n",
    "with open(further_processing_file, 'w', encoding='utf-8') as f:\n",
    "    for entry in further_processing:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Total courses processed: {len(df)+len(special_treatment_df)}\")\n",
    "print(f\"Valid prerequisites: {len(valid_prerequisites)}\")\n",
    "print(f\"No prerequisites: {len(no_prerequisites)}\")\n",
    "print(f\"Needing further processing: {len(further_processing)}\")\n"
   ],
   "id": "528d3ee9bd127b88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total courses processed: 1945\n",
      "Valid prerequisites: 1280\n",
      "No prerequisites: 383\n",
      "Needing further processing: 282\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save the prerequisites in JSON Lines format",
   "id": "87d3103e07d8f634"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T16:40:47.178211Z",
     "start_time": "2024-10-13T16:40:47.133050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load the CSV file for validation (df) and the valid prerequisites JSON Lines file\n",
    "file_path = 'general_rule_courses.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "valid_prerequisites_file = 'valid_prerequisites.jsonl'\n",
    "\n",
    "# Load valid prerequisites from JSONL\n",
    "valid_prerequisites = []\n",
    "with open(valid_prerequisites_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        valid_prerequisites.append(json.loads(line))\n",
    "\n",
    "# Convert valid_prerequisites list into a DataFrame\n",
    "valid_prerequisites_df = pd.DataFrame(valid_prerequisites)\n",
    "\n",
    "# Convert both 'Course' and 'course_code' to strings for a consistent merge\n",
    "df['Course'] = df['Course'].astype(str)\n",
    "valid_prerequisites_df['course_code'] = valid_prerequisites_df['course_code'].astype(str)\n",
    "\n",
    "# Merge df with valid prerequisites DataFrame\n",
    "merged_df = pd.merge(df, valid_prerequisites_df, how='left', left_on='Course', right_on='course_code')\n",
    "\n",
    "# Replace NaN in the 'parsed_prerequisites' column with empty strings for courses with no prerequisites\n",
    "merged_df['parsed_prerequisites'].fillna('', inplace=True)\n",
    "\n",
    "# Drop the duplicate 'course_code' column\n",
    "merged_df.drop(columns=['course_code'], inplace=True)\n",
    "merged_df.to_csv('validation.csv')\n",
    "\n",
    "# Create a dictionary for easy lookup\n",
    "course_prerequisites = {}\n",
    "for index, row in merged_df.iterrows():\n",
    "    course_code = str(row['Course'])\n",
    "    prerequisites = row['parsed_prerequisites'] if row['parsed_prerequisites'] else ''\n",
    "    course_prerequisites[course_code] = prerequisites\n",
    "\n",
    "# You can save the final data structure (course_prerequisites) to a JSON file for persistence if needed\n",
    "course_prerequisites_file = 'course_prerequisites.json'\n",
    "with open(course_prerequisites_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(course_prerequisites, f, ensure_ascii=False, indent=4)"
   ],
   "id": "aafc029fdd79a84e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p3/1syz8hg56wvffghj9y_06hz80000gn/T/ipykernel_52458/2599797649.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['parsed_prerequisites'].fillna('', inplace=True)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Validate the prerequisites for a few courses",
   "id": "f4ac458889319bd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T16:34:58.135085Z",
     "start_time": "2024-10-13T16:34:58.128896Z"
    }
   },
   "cell_type": "code",
   "source": "merged_df.head(10)",
   "id": "3ff3734c57fa4347",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Course                                      Prerequisites  \\\n",
       "0   2402  01001/01003/01002/01004/01005/01901, At the la...   \n",
       "1  28213                                        26400.26222   \n",
       "2  41632         41612, Product Design and\\r\\nDocumentation   \n",
       "3  41656                     41661/41650/41659/41680.­41684   \n",
       "4  41661  41650/41657/41659/41681/41683/41680/41686.­416...   \n",
       "5  41667  41650/41657/41659/41681/41683/41658/41680/4168...   \n",
       "6  41737  Knowledge of strength of materials, and plasti...   \n",
       "7  41738  Knowlegde of polymer materials and polymer pro...   \n",
       "8  41744  41703/41781.41650/41659, or equivalent Product...   \n",
       "9  41747  Knowledge of basic process technology 42201/42...   \n",
       "\n",
       "                                parsed_prerequisites  \n",
       "0  (01001 or 01003 or 01002 or 01004 or 01005 or ...  \n",
       "1                                (26400) and (26222)  \n",
       "2                                            (41612)  \n",
       "3     (41661 or 41650 or 41659 or 41680) and (41684)  \n",
       "4  (41650 or 41657 or 41659 or 41681 or 41683 or ...  \n",
       "5  (41650 or 41657 or 41659 or 41681 or 41683 or ...  \n",
       "6                                (41501) and (41650)  \n",
       "7  (41736 or 41737 or 41785 or 42231 or 42233 or ...  \n",
       "8              (41703 or 41781) and (41650 or 41659)  \n",
       "9  (42201 or 42911 or 41704 or 41784) and (41659)...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course</th>\n",
       "      <th>Prerequisites</th>\n",
       "      <th>parsed_prerequisites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2402</td>\n",
       "      <td>01001/01003/01002/01004/01005/01901, At the la...</td>\n",
       "      <td>(01001 or 01003 or 01002 or 01004 or 01005 or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28213</td>\n",
       "      <td>26400.26222</td>\n",
       "      <td>(26400) and (26222)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41632</td>\n",
       "      <td>41612, Product Design and\\r\\nDocumentation</td>\n",
       "      <td>(41612)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41656</td>\n",
       "      <td>41661/41650/41659/41680.­41684</td>\n",
       "      <td>(41661 or 41650 or 41659 or 41680) and (41684)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41661</td>\n",
       "      <td>41650/41657/41659/41681/41683/41680/41686.­416...</td>\n",
       "      <td>(41650 or 41657 or 41659 or 41681 or 41683 or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41667</td>\n",
       "      <td>41650/41657/41659/41681/41683/41658/41680/4168...</td>\n",
       "      <td>(41650 or 41657 or 41659 or 41681 or 41683 or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41737</td>\n",
       "      <td>Knowledge of strength of materials, and plasti...</td>\n",
       "      <td>(41501) and (41650)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41738</td>\n",
       "      <td>Knowlegde of polymer materials and polymer pro...</td>\n",
       "      <td>(41736 or 41737 or 41785 or 42231 or 42233 or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41744</td>\n",
       "      <td>41703/41781.41650/41659, or equivalent Product...</td>\n",
       "      <td>(41703 or 41781) and (41650 or 41659)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41747</td>\n",
       "      <td>Knowledge of basic process technology 42201/42...</td>\n",
       "      <td>(42201 or 42911 or 41704 or 41784) and (41659)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test the prerequisites",
   "id": "513a92f8c5be3842"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T16:35:01.940484Z",
     "start_time": "2024-10-13T16:35:01.936332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the JSON file into a Python dictionary\n",
    "with open(course_prerequisites_file, 'r', encoding='utf-8') as f:\n",
    "    course_prerequisites = json.load(f)\n",
    "\n",
    "def check_prerequisites(course_code, passed_courses, course_prerequisites):\n",
    "    # Get the prerequisites expression for the course\n",
    "    prerequisites = course_prerequisites.get(course_code, '')\n",
    "\n",
    "    # If there are no prerequisites, return True\n",
    "    if not prerequisites:\n",
    "        return True\n",
    "\n",
    "    # For each course number, replace it with the corresponding condition (True/False)\n",
    "    course_numbers = re.findall(r'\\d{4,5}', prerequisites)  # Find all 4- or 5-digit numbers\n",
    "    for course in course_numbers:\n",
    "        prerequisites = prerequisites.replace(course, f'({course in passed_courses})')\n",
    "\n",
    "    # Evaluate the expression\n",
    "    try:\n",
    "        return eval(prerequisites)\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating prerequisites for {course_code}: {e}\")\n",
    "        return False\n",
    "\n",
    "course_code = '41525'\n",
    "passed_courses = {'02002', '41564'}\n",
    "print(check_prerequisites(course_code, passed_courses, course_prerequisites)) # Should be true as the student has met the prerequisites\n",
    "\n",
    "course_code = '10240'\n",
    "passed_courses = {'02002', '41564'}\n",
    "print(check_prerequisites(course_code, passed_courses, course_prerequisites)) # Should be false as the student has not met  prerequisites\n",
    "\n",
    "course_code = '12345'\n",
    "passed_courses = {'02002', '41564'}\n",
    "print(check_prerequisites(course_code, passed_courses, course_prerequisites)) # Should be true as the course is not covered in course_prerequisites"
   ],
   "id": "ed5826e2b8e96c51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6f7d62d1013128ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
